{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice 2 Text Normalization\n",
    "***\n",
    "Rodriguez Nuñez Diego Eduardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect information from different sources\n",
    "• Get news using RSS feeds from La Jornada and Expansión platforms using the following URLs:\n",
    "\n",
    "    • https://www.jornada.com.mx/v7.0/cgi/rss.php\n",
    "\n",
    "    • https://expansion.mx/canales-rss\n",
    "    \n",
    "• The data collection should be done once a day during 5 days at agreed time\n",
    "\n",
    "• News can be repeated from one day to the next, so you must avoid collecting it again\n",
    "\n",
    "• For each news article extract:\n",
    "\n",
    "    • Title (<title>)\n",
    "    • Content summary (<description>)\n",
    "    • Section\n",
    "    • URL (<link>)\n",
    "    • Date of publication (<pubDate>)\n",
    "\n",
    "• Section of interest are:\n",
    "\n",
    "    • Sports\n",
    "    • Economy\n",
    "    • Science and technology\n",
    "    • Culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "    \"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Apr\": \"04\", \"May\": \"05\", \"Jun\": \"06\",\n",
    "    \"Jul\": \"07\", \"Aug\": \"08\", \"Sep\": \"09\", \"Oct\": \"10\", \"Nov\": \"11\", \"Dec\": \"12\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Source', 'Title', 'Content', 'Section', 'URL', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date):\n",
    "    match = re.match(r\"\\w{3}, (\\d{2}) (\\w{3}) (\\d{4})\", date)\n",
    "    if match:\n",
    "        day = match.group(1)    # Extrae el día\n",
    "        month_str = match.group(2)  # Extrae el mes como texto\n",
    "        year = match.group(3)   # Extrae el año\n",
    "\n",
    "        # Convertir el mes de texto a su correspondiente número\n",
    "        month = months.get(month_str, \"00\")  # Si no encuentra el mes, devuelve \"00\"\n",
    "        \n",
    "        # Formatear en dd/mm/yyyy\n",
    "        formatted_date = f\"{day}/{month}/{year}\"\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return None # Retorna None si no se puede extraer la fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_jornada_urls = [\"https://www.jornada.com.mx/rss/deportes.xml?v=1\",\"https://www.jornada.com.mx/rss/economia.xml?v=1\",\"https://www.jornada.com.mx/rss/ciencias.xml?v=1\",\"https://www.jornada.com.mx/rss/cultura.xml?v=1\"]\n",
    "expansion_urls = [\"https://www.expansion.mx/rss/economia\",\"https://www.expansion.mx/rss/tecnologia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(url):\n",
    "    feed = feedparser.parse(url)\n",
    "    news = []\n",
    "\n",
    "    # Check if 'title' exists in the feed, otherwise use 'Unknown Source'\n",
    "    fuente = feed.feed.get('title', 'Unknown Source')\n",
    "\n",
    "    # Match and extract section, or set it to 'Unknown Section' if not found\n",
    "    section_match = re.search(r\"[-:]\\s*(\\w+)\", fuente)\n",
    "    section = section_match.group(1) if section_match else 'Unknown Section'\n",
    "    \n",
    "    # Loop through entries and collect data\n",
    "    for entry in feed.entries:\n",
    "        # Extract the date in dd/mm/yyyy format\n",
    "        formatted_date = format_date(entry.get('published', 'No Date'))\n",
    "        news.append({\n",
    "            'Source': fuente,\n",
    "            'Title': entry.get('title', 'No Title'),\n",
    "            'Content': entry.get('description', 'No Description'),\n",
    "            'Section': section,\n",
    "            'URL': entry.get('link', 'No URL'),\n",
    "            'Date': formatted_date\n",
    "        })\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved\n"
     ]
    }
   ],
   "source": [
    "for url_list in [la_jornada_urls, expansion_urls]:\n",
    "    for url in url_list:\n",
    "        news = get_news(url)\n",
    "        df = pd.DataFrame(news)\n",
    "        df.to_csv(\"raw_data_corpus.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates: 77\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_data_corpus.csv\")\n",
    "print(\"duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acumulado = pd.read_csv(\"raw_data_corpus.csv\")\n",
    "df_final = df_acumulado.drop_duplicates(subset=['Title', 'Content','URL'])\n",
    "df_final.to_csv(\"raw_data_corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Data Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stop = {\"ADP\",\"AUX\",\"CCONJ\",\"DET\",\"NUM\",\"PART\",\"PRON\", \"SCONJ\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Tokenización\n",
    "    doc = nlp(text)\n",
    "    normalized_tokens = []\n",
    "    for token in doc:\n",
    "        # Eliminar tokens según su categoría gramatical\n",
    "        if token.pos_ not in stop:\n",
    "            # Lematización\n",
    "            normalized_tokens.append(token.lemma_)\n",
    "    return \" \".join(normalized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"raw_data_corpus.csv\")\n",
    "df2['Content'] = df2['Content'].astype(str)\n",
    "df2['Title'] = df2['Title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Content'] = df2['Content'].apply(normalize_text)\n",
    "df2['Title'] = df2['Title'].apply(normalize_text)\n",
    "\n",
    "df2.to_csv(\"normalized_data_corpus_prueba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acum = pd.read_csv(\"normalized_data_corpus_prueba.csv\")\n",
    "df_norm = pd.concat([df_acum, df2])\n",
    "df_norm = df_norm.drop_duplicates(subset=['Title', 'Content', 'URL'])\n",
    "df_norm.to_csv(\"normalized_data_corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
